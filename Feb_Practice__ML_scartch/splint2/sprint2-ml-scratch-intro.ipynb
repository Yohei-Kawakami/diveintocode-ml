{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice of scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>次回から機械学習手法のスクラッチを行っていきます。\n",
    "<br>Sprint2ではその準備として、scikit-learnのtrain_test_splitのスクラッチと、分類・回帰のパイプラインの作成を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The purpose of this practice\n",
    "###### 1, Getting used to dealing with 'py.file'\n",
    "###### 2, Preparing scratch of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The significance of Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、\n",
    "<br>scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "<br>\n",
    "<br>スクラッチをすることでscikit-learnを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。\n",
    "<br>コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "<br>\n",
    "<br>以下のような効果を狙っています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1, Make it easier to understand new theories and mathematical expression\n",
    "###### 2, Avoid ambiguity in using library\n",
    "###### 3. Make easier to read implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execute py.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまでの課題ではJupyter Notebookを用いてコーディングを行ってきました。\n",
    "<br>しかし、大きめのプログラムを書いていくにあたってはpyファイルを作成して実行する必要があります。\n",
    "<br>\n",
    "<br>今回からのスクラッチ編の課題は、最終的にpyファイルをJupyter Notebook上から実行する形で作成していただきます。\n",
    "<br>\n",
    "<br>任意のテキストエディタを用いて、ipynbと同じ階層に hello.py を作成してください。\n",
    "<br>セルに%run hello.pyとすることでJupyter Notebook上から実行が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'hello.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run hello.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>pyファイルに対しては実行する際に引数を与えることが可能です。\n",
    "<br>今後はモデルのハイパーパラメータやデータセットのパスを引数として渡せるようにしていきます。\n",
    "<br>標準モジュールargparseを利用したサンプルコードを用意しました。ipynbと同じ階層に hello_argparse.py を作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library and module\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# setting of arguments in command line\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description='argparse sample')\n",
    "parser.add_argument('--num_iters', default=10, type=int,\n",
    "                    help='number of iterations')\n",
    "parser.add_argument('--alpha', default=0.1, type=float,\n",
    "                    help='initial alpha')\n",
    "parser.add_argument('--display', action='store_true',\n",
    "                    help='display of calculation process')\n",
    "parser.add_argument('--text', default='Hello, World!', type=str,\n",
    "                    help='text sample')\n",
    "\n",
    "def main(args):\n",
    "    print(args.text)\n",
    "    x = args.alpha\n",
    "    for i in range(args.num_iters):\n",
    "        x *= 2\n",
    "        if args.display:\n",
    "            print(x)\n",
    "    print(\"RESULT : {}\".format(x))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # running first when pyfile start\n",
    "\n",
    "    # read a argument of command line\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'hello_argparse.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run hello_argparse.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>引数alphaに引数num_iters回2倍した結果を出力するプログラムです。\n",
    "<br>計算過程を表示するかどうかは引数displayにより指定できます。また、引数textの文章も出力します。\n",
    "<br>引数4種類をまとめると以下のようになります。\n",
    "<br>\n",
    "<br>num_iters : ループの回数。整数値。デフォルト10。\n",
    "<br>alpha : 計算のための初期値。実数値。デフォルト0.1。\n",
    "<br>display : 計算過程を表示するかどうか。デフォルトではFalse、引数に指定するとTrueになる。\n",
    "<br>text : 表示する文章。文字列。デフォルト「Hello, World!」。\n",
    "<br>\n",
    "<br>何も指定せずに実行すると、デフォルトで指定した値が代入されます。\n",
    "<br>%run hello_argparse.py\n",
    "<br>\n",
    "<br>以下のように引数を与えることが可能です。\n",
    "<br>%run hello_argparse.py --display --alpha 0.3 --text \"Hello, argparse!\" --num_iters 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'hello_argparse.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run hello_argparse.py --display --alpha 0.3 --text \"Hello, argparse!\" --num_iters 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a directory in Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>スクラッチのコードを管理するため、「diveintocode-term1」配下に以下のような構造で「ml-scratch」を作成してください。\n",
    "<div>この構造は一例なので、随時自分なりに追加、変更していってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>utils : 手法に関わらず共通して使うコードを格納\n",
    "<br>model : 各種モデルのコードを格納\n",
    "<br>\n",
    "<br>この後作成するtrain_test_splitなどの関数は複数のSprintで使用するため、utilsの中に置いておき、それをインポートして使えるようにしていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK1. Scratch of train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>まずはスクラッチの練習として、scikit-learnのtrain_test_splitを自作してみましょう。\n",
    "<div>Jupyter Notebookでコーディングを進め、完成後はpyファイルとします。utilsディレクトリの中にsplit.pyを作ってください。\n",
    "<div>sklearn.model_selection.train_test_split — scikit-learn 0.20.0 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "def train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    split the train data and test data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "      learning data\n",
    "    y : ndarray, shape (n_samples, )\n",
    "      correct value\n",
    "    train_size : float (0<train_size<1)\n",
    "      % of train data in whole data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : ndarray, shape (n_samples, n_features)\n",
    "      learning data\n",
    "    X_test : ndarray, shape (n_samples, n_features)\n",
    "      test data\n",
    "    y_train : ndarray, shape (n_samples, )\n",
    "      correct vale of train data\n",
    "    y_test : ndarray, shape (n_samples, )\n",
    "      correct vale of test data\n",
    "    \"\"\"\n",
    "    train_len = int(len(X)*train_size)\n",
    "    X_train, X_test = X [:train_len, train_len:]\n",
    "    y_train, y_test = y[:train_len, train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>テストの重要性\n",
    "<br>scikit-learnのtrain_test_splitと同じ動作をしているか必ずテストをするようにしましょう。ライブラリが存在するものをスクラッチする学習方法は動作の正しさを確認しやすいという利点があります。\n",
    "<br>\n",
    "<br>インポートの方法\n",
    "<br>ml-scratchディレクトリの下にあるutilsディレクトリの中のsplit.pyの中のtrain_test_splitをimportする場合、次のように書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "X = np.random.randint(100, size=100)\n",
    "X.shape = (10,10)\n",
    "\n",
    "y = np.random.randint(100, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[35, 94, 82, 20, 14, 91, 81, 22, 64, 43],\n",
       "        [ 1, 92, 38, 43, 76, 73, 93, 51, 46, 91],\n",
       "        [14, 74, 67, 17, 41, 84, 64, 53, 85, 74]]),\n",
       " array([[ 5,  2, 76, 37, 76, 17, 41, 40, 64, 24],\n",
       "        [67, 96, 42, 97, 25, 74, 95, 21, 40, 45],\n",
       "        [ 0, 28, 49, 80, 74, 87, 69, 53, 50, 99],\n",
       "        [90, 25, 54, 21, 74, 62, 28, 53, 85, 47],\n",
       "        [21, 14, 45, 36, 65, 10, 64, 66, 35,  9],\n",
       "        [35, 39,  1, 12, 87, 42, 26, 45, 67, 95],\n",
       "        [17, 48, 88, 35, 18, 34, 41, 26, 23,  7]]),\n",
       " array([99, 18, 74]),\n",
       " array([99, 83, 67, 63, 38, 58, 55]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.split import train_test_split\n",
    "train_test_split(X, y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[35, 94, 82, 20, 14, 91, 81, 22, 64, 43],\n",
       "        [ 1, 92, 38, 43, 76, 73, 93, 51, 46, 91],\n",
       "        [14, 74, 67, 17, 41, 84, 64, 53, 85, 74]]),\n",
       " array([[ 5,  2, 76, 37, 76, 17, 41, 40, 64, 24],\n",
       "        [67, 96, 42, 97, 25, 74, 95, 21, 40, 45],\n",
       "        [ 0, 28, 49, 80, 74, 87, 69, 53, 50, 99],\n",
       "        [90, 25, 54, 21, 74, 62, 28, 53, 85, 47],\n",
       "        [21, 14, 45, 36, 65, 10, 64, 66, 35,  9],\n",
       "        [35, 39,  1, 12, 87, 42, 26, 45, 67, 95],\n",
       "        [17, 48, 88, 35, 18, 34, 41, 26, 23,  7]]),\n",
       " array([99, 18, 74]),\n",
       " array([99, 83, 67, 63, 38, 58, 55]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.split\n",
    "utils.split.train_test_split(X, y, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>ただし、importできるのは実行しているファイルよりも下の階層にある場合です。\n",
    "<br>そのような関係にない場所から呼び出したい場合は、sys.path.appendを使い、モジュールを探しに行く場所を追加する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(ml-scratchディレクトリへのpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>次回以降、scikit-learnと同じ動作をするクラスを作成していきますが、\n",
    "<br>まずはscikit-learnを使ったコードを用意しておきます。\n",
    "<br>\n",
    "<br>ここまでの復習を兼ねていますので、学んだことを思い出しながら使いやすいコードを完成させてください。\n",
    "<br>argparseを使って、外から引数を入れられるようにもしておきましょう。\n",
    "<br>\n",
    "<br>このコードを元に、Sprintが進むごとに呼び出すクラスを自作のものに変えていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK2. Create piplines of Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>分類は3種類の手法を扱います。pyファイルで実行できる分類のパイプラインを作成してください。\n",
    "<br>\n",
    "<br>・ロジスティック回帰\n",
    "<br>・SVM\n",
    "<br>・決定木\n",
    "<br>データセットは3種類用意します。3つのデータセットが引数により切り替えられるようにしてください。\n",
    "<br>1つ目は事前学習期間同様にirisデータセットです。\n",
    "<br>\n",
    "<br>sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation\n",
    "<br>\n",
    "<br>2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "<br>virgicolorとvirginica\n",
    "<br>また、残り2つは可視化が可能な特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。\n",
    "<br>「シンプルデータセット1」「シンプルデータセット2」とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#  iris\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "df_X = pd.DataFrame(data.data)\n",
    "df_y = pd.DataFrame(data.target)\n",
    "\n",
    "df_X = df_X.rename(columns={0:'sepal_length', 1:'sepal_width', 2:'petal_length', 3:'petal_width'})\n",
    "df_y = df_y.rename(columns={0:'target'})\n",
    "\n",
    "df = pd.concat([df_X, df_y], axis=1)\n",
    "\n",
    "columns_list = []\n",
    "\n",
    "df_process = df[df['target'] > 0]\n",
    "\n",
    "iris_X = df_process.drop('target', axis=1) # array\n",
    "iris_y = pd.DataFrame(df_process['target']-1) # array\n",
    "\n",
    "iris_X.to_csv(\"classifier_X.csv\", encoding=\"shift_jis\")\n",
    "iris_y.to_csv(\"classifier_y.csv\", encoding=\"shift_jis\")\n",
    "\n",
    "print(len(iris_X))\n",
    "print(len(iris_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple dataset1\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0= [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "sd1_X = X[random_index]\n",
    "sd1_y = y[random_index]\n",
    "\n",
    "sd1_X = pd.DataFrame(sd1_X)\n",
    "sd1_y = pd.DataFrame(sd1_y)\n",
    "\n",
    "sd1_X.to_csv(\"classifier_X.csv\", encoding=\"shift_jis\")\n",
    "sd1_y.to_csv(\"classifier_y.csv\", encoding=\"shift_jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  simple dataset2\n",
    "sd2_X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "sd2_y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "sd2_X = pd.DataFrame(sd2_X)\n",
    "sd2_y = pd.DataFrame(sd2_y)\n",
    "\n",
    "sd2_X.to_csv(\"classifier_X.csv\", encoding=\"shift_jis\")\n",
    "sd2_y.to_csv(\"classifier_y.csv\", encoding=\"shift_jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model MODEL]\n",
      "                             [--normalization NORMALIZATION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/KawakamiYohei/Library/Jupyter/runtime/kernel-84fa05c0-2ec1-4467-b62b-43ad4b8f18a9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tesflowmachine/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import library and module\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# initialize argument value\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description='argparse sample')\n",
    "parser.add_argument('--model', default=LogisticRegression(),\n",
    "                    help='method')\n",
    "parser.add_argument('--normalization', default=True, type=bool,\n",
    "                    help='normalization')\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---------------\n",
    "    model : the model of method\n",
    "    target_value :train data\n",
    "    feature_value : objective valuable\n",
    "    normalization :name, True= standardize　False= no standardize\n",
    "\n",
    "    \"\"\"\n",
    "    X = pd.read_csv('classifier_X.csv', index_col=0)\n",
    "    y = pd.read_csv('classifier_y.csv', index_col=0)\n",
    "\n",
    "    # split train data and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # standalized\n",
    "    if args.normalization == True:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        scaler.fit(X_test)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # pick\n",
    "    y_train, y_test = y_train.iloc[:, 0], y_test.iloc[:, 0]\n",
    "\n",
    "    # learnig and predicting\n",
    "    if args.model == 'LogisticRegression()':\n",
    "        clf = LogisticRegression()\n",
    "\n",
    "    elif args.model == 'DecisionTreeClassifier()':\n",
    "        clf = DecisionTreeClassifier()\n",
    "\n",
    "    elif args.model == 'SVC()':\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.probability = True\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict_proba(X_test)\n",
    "\n",
    "    return print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # running first when pyfile start\n",
    "\n",
    "    # read a argument of command line\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "%run clf.py  --model DecisionTreeClassifier() --normalization False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK3. Create a  pipline of Linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>回帰は1種類を扱います。pyファイルで実行できる回帰のパイプラインを作成してください。\n",
    "<br>\n",
    "<br>・線形回帰\n",
    "<br>データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "<br>House Prices: Advanced Regression Techniques\n",
    "<br>train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "house_X = df_train.loc[:, ['GrLivArea', 'YearBuilt']]\n",
    "house_y = df_train['SalePrice']\n",
    "y = y.rename(columns={0:'SalesPrice'})\n",
    "\n",
    "house_X.to_csv(\"linear_X.csv\" )\n",
    "house_y.to_csv(\"linear_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model MODEL]\n",
      "                             [--normalization NORMALIZATION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/KawakamiYohei/Library/Jupyter/runtime/kernel-84fa05c0-2ec1-4467-b62b-43ad4b8f18a9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tesflowmachine/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import library and module\n",
    "import argparse\n",
    "\n",
    "# import library module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# initialize argument value\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description='argparse sample')\n",
    "parser.add_argument('--model', default=LinearRegression(), type=str, \n",
    "                    help='model')\n",
    "parser.add_argument('--normalization', default=True, type=bool,\n",
    "                    help='normalization')\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---------------\n",
    "    model : the model of method\n",
    "    target_value :train data\n",
    "    feature_value : objective valuable\n",
    "    normalization :name, True= standardize　False= no standardize\n",
    "    \n",
    "    \"\"\"\n",
    "    X = pd.read_csv('linear_X.csv')\n",
    "    y = pd.read_csv('linear_y.csv')\n",
    "    \n",
    "    # split train data and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # standalized\n",
    "    if args.normalization == True:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        scaler.fit(X_test)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    # pick\n",
    "    y_train, y_test = y_train.iloc[:, 0], y_test.iloc[:, 0]\n",
    "    \n",
    "    # learnig and predicting\n",
    "    if args.model == 'LinearRegression()':\n",
    "        clf = LinearRegression()\n",
    "    clf.fit(X_train,  y_train)\n",
    "    result = clf.predict_proba(X_test)\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # running first when pyfile start\n",
    "\n",
    "    # read a argument of command line\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235089.19016343 125750.01902351 252902.15204646 516107.38041869\n",
      " 220684.88599981 122302.48377137 182738.89028805 293793.42008939\n",
      " 132768.55115969 147133.97779058 150993.93533302 109864.14556224\n",
      " 176050.29301263 246361.18753339 220504.68057105 161092.76283009\n",
      " 203291.69960822 127058.73609353  75567.42596738  74760.97181833\n",
      " 188345.73082349 200359.5611771  204779.57377218 216337.37193868\n",
      " 226311.16530161 189609.78966188 170636.791806   268123.94758954\n",
      "  90246.50855453 137350.90291941 298733.54701219  81032.41443937\n",
      " 230532.58203639 129746.57209789 221239.16035356 313463.06852987\n",
      " 148789.97181809  67111.98276519 191569.97491746 153017.69341919\n",
      "  99295.1036432  226189.27617194 120188.36088711 126090.99111467\n",
      " 113937.40536726 201241.67372196 110122.63022386 196260.03357199\n",
      " 118151.4689009  124030.45216542 169315.98917075 185788.18548476\n",
      " 151123.70183124 190422.02450984 143078.5842497  143383.29964519\n",
      " 221774.52010835 143156.86348256 141294.3962262   35828.84069617\n",
      " 105051.67361063 191297.30802097 240709.68876632 210656.98453447\n",
      " 234772.91337013 244363.17307991 124055.67163069  55305.67397525\n",
      " 235695.47594995 124983.490742   291988.74496471 127032.99246085\n",
      " 180856.98426533 154848.11217655 188178.13512736 186606.20103162\n",
      " 222205.8569976  203297.48030712 231460.40114771 173046.18021496\n",
      " 185472.43285887 212925.5692148  309389.28455745  47339.88396139\n",
      " 229414.04443332 258141.22852324 143241.44758174 105978.96855453\n",
      " 153585.10167298 217617.20037156 103123.53685404 198566.97161764\n",
      " 132344.56747158 124899.95497764  86717.01004026 207679.6637043\n",
      " 210914.94502868 284764.26376708 278267.95748565 252463.46195607\n",
      " 187541.37334408 231022.23522473 120954.88916862 124416.08248821\n",
      " 173730.22106693 187540.32500926 204831.06103754 215948.07244401\n",
      "  44536.46369367 227548.95633991 196981.90362186 197793.61430241\n",
      " 112783.67426072  97930.69111114  61466.26469702  75308.94130576\n",
      " 170893.70396539 112648.12706359 143078.5842497  192380.11309578\n",
      " 207705.40733698 128657.46215677 208827.08994452 159360.58623936\n",
      " 123765.13847006 107931.27644157 275219.71062376 214034.11792229\n",
      " 255453.91668628 170218.5888168  287026.01941369  56762.02380763\n",
      " 103948.38143464 226697.84395923  52919.93252933 194858.84017685\n",
      " 282270.81542635 127613.01044727 219009.45320594 275673.63128384\n",
      " 124757.57874678 327337.2694702  184679.63677727 185371.55499779\n",
      " 208942.67420787 114607.26398436 192466.26969719 196363.00810271\n",
      "  86781.10703826 284024.00328567  93792.81014071 117243.61272336\n",
      " 191098.18799326 237262.15351419 219048.33073867 204561.53914551\n",
      "  92844.50392821 221355.26878432 257582.22180541 206500.7131325\n",
      " 180781.32586952 162583.78199852 223198.29727432 161975.92370977\n",
      " 128458.34212905 252471.33932462 193870.08392939 151470.45462131\n",
      " 142441.82246641 229883.73468789 195287.03206163 139910.54492778\n",
      " 145561.51952744 246154.19013713 326828.70168291 113949.49093248\n",
      " 216457.16439871 132473.80980239  88650.40332834 135900.33378593\n",
      " 144684.66351407 142602.58912881 236783.53755625 205141.03296453\n",
      " 251393.79078131 250781.72429589 133915.45323249 208092.0859946\n",
      " 238588.21268093 193024.75224761 209213.76860213 247243.30007825\n",
      " 318850.30193641 125964.36962091  66028.65352297 300394.79757119\n",
      " 154010.13369591 142100.32620784 227374.53161006 108557.52516186\n",
      " 222915.11731483 210624.93603547 155170.16966876 129082.4941797\n",
      " 200308.59807915 226713.59869633 226407.83496602 128779.35128644\n",
      " 168174.34362944 109619.31896807 113655.27374259 122130.67987857\n",
      " 189944.98105413 198341.58378983 275580.6456487   86264.66188242\n",
      " 193521.75863709 146458.33847458 241140.50148816 201932.01944024\n",
      " 220220.97644415 191078.22505948 187702.14000648 177480.89921233\n",
      " 203838.62076082 243563.54796458 115683.76419285  78261.04267065\n",
      " 153223.64248063  71765.78472404  93443.960681    99488.96713941\n",
      " 229629.98239035 132272.59310503 177106.30611993 248596.67537991\n",
      " 181721.23054606 145476.41126085 126968.37129544 159939.03172355\n",
      " 151774.64584939  76204.71191808 227838.44116571 104746.95821514\n",
      " 124997.67297687 221806.56860735 134057.82946335 229347.85076569\n",
      " 127844.7031414  123393.16621473 193248.02854838 187135.78008751\n",
      " 245909.36354296  99965.48642771 212893.52071581 336469.40032322\n",
      " 102016.03648138 231872.823438   204154.89755412 162775.02465768\n",
      " 190111.52841544 116322.62264577 248590.37051359 102137.40144364\n",
      " 276588.84066252 250942.49095829 215174.71512878 142086.14397297\n",
      " 109626.1480018  324701.44489861 263773.81269135 179433.20709936\n",
      " 252631.0576522  149042.15161339 137743.88644334 127058.21192612\n",
      "  55904.60656063 183699.80623318  78048.26457548 200158.86864715\n",
      " 230803.15226324  88261.62800108 215438.98048931 307384.96523764\n",
      " 103942.60073573 173706.57410389 235997.57050838 239941.58798259\n",
      " 209999.73565    215754.7331152  143557.72437504 110882.32947164\n",
      " 277610.70860118 202053.90856991 124222.7431594  165521.17696113\n",
      " 188854.82277819 275707.25228507 184388.57944924  91279.39886621\n",
      " 200223.48981255 208697.84761371 111649.38192056 128373.23386246\n",
      " 190067.39435122 153699.63760151 138890.78851614 182353.25996526\n",
      " 226822.35392596 262536.54582046 218667.95694737 216124.0696761\n",
      " 261337.63231489 229604.23875767 138028.63890506 205552.93108741\n",
      " 226311.16530161 187045.41528942 265539.61028331 224886.86396823\n",
      " 211262.74615357 183370.39553984 145374.48506495 183228.54347639\n",
      " 200269.19637901 152058.34997628  65797.48499625 236802.97632261\n",
      " 155976.0996504  110882.32947164 212120.16340057 145174.84086982\n",
      " 105842.89718999 189171.6237389  185002.7426043  194661.83167616\n",
      " 144241.76522701 115709.50782553 108047.38487233 280995.19519015\n",
      " 194339.25001654 142086.14397297 160147.07745464 238588.21268093\n",
      " 243183.17417328 259088.48640091 149294.3314087  204554.18594438\n",
      " 281936.14820151 115200.41587083 144685.71184889 230158.51311141\n",
      " 193784.9756628  167723.56797383 228830.88144243 160313.10064854\n",
      " 115993.21195242 211179.21038921  86974.44636707 116979.34736283\n",
      " 126510.24243869 255151.29796044 276888.83855131 156883.95582794\n",
      " 121303.73862833 193775.51093463 157870.09123834 118204.52866849\n",
      " 183805.92576837 216613.19869703 119544.7700701  169954.32345626\n",
      " 159159.369542    98027.36077554 125473.14393034 219216.97476962\n",
      " 227123.40014957 190802.92246855  93547.98354654 209678.2023252\n",
      "  59964.7324656  214568.95350967 208493.99522191 188637.31231893\n",
      " 242661.47248595 183808.56146281 140708.59754087 115040.69754325\n",
      " 246476.24762934 111294.75176194  98613.15946087 247443.46844079\n",
      "  68864.64645709 278777.04944035 253070.27191     36222.87255492\n",
      " 142391.38353588 172698.37909007 162006.92387394 177520.30091246\n",
      " 217334.02041208 287825.64452902 158664.98398958  66222.51701919\n",
      " 126124.08794849 229720.34718843 193952.57135892 182147.31090381\n",
      " 129043.09247956 191103.96869216 222392.89146009 183054.64291394\n",
      " 157283.7683856  168476.96235529  81250.97323345 229553.79982713\n",
      " 174600.24804657 276199.01700044 175289.02126262 286755.44918684\n",
      " 165505.94639144 219589.47119237 206983.53728711 118874.38728559\n",
      " 253817.36142514 172403.63773277 197342.31447938 135558.83752736\n",
      " 109567.83170271 137646.69261153 152103.53237533 231906.44443924\n",
      " 196757.03996146 217585.15187256 312264.67919171 225035.020898\n",
      " 297273.00384053 190730.42393459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tesflowmachine/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/KawakamiYohei/gitrepos/diveintocode-ml/splint2/lnr.py:41: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  X_train = scaler.transform(X_train)\n",
      "/anaconda/envs/tesflowmachine/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/KawakamiYohei/gitrepos/diveintocode-ml/splint2/lnr.py:43: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  X_test = scaler.transform(X_test)\n"
     ]
    }
   ],
   "source": [
    "%run lnr.py  --model LinearRegression() --normalization False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
